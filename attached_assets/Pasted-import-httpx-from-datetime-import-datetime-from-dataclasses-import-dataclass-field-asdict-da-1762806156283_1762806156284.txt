import httpx
from datetime import datetime
from dataclasses import dataclass, field, asdict

@dataclass
class OAuthConfig:
    """Class for keeping track of OAuth token configs."""
    token_url: str = field(repr=False)
    client_id: str
    client_secret: str
    grant_type: str
    scope: str
    early_refresh_seconds: int = field(default=300, repr=False) # refresh token before "expires_in"
    def oauth_payload(self) -> dict:
        return {k: v for k, v in asdict(self).items() if k != 'self' and k in self.__dataclass_fields__ and self.__dataclass_fields__[k].repr}

class OAuthTokenFetcher:
    """Class for fetching and caching an OAuth token. Handles refetching before token expires"""
    OAUTH_HEADERS = {"Content-Type": "application/x-www-form-urlencoded"}

    def __init__(self, oauth_config: OAuthConfig) -> None:
        self._oauth_config = oauth_config
        self._fetch_token()

    def _fetch_token(self) -> str:
        response = httpx.post(url=self._oauth_config.token_url, data=self._oauth_config.oauth_payload(), headers=self.OAUTH_HEADERS)
        response.raise_for_status()
        self._token = response.json()
        self.refresh_after = datetime.now().timestamp() + self._token["expires_in"] - self._oauth_config.early_refresh_seconds
        return self._token

    def get_token(self) -> str:
        if datetime.now().timestamp() > self.refresh_after:
            self._fetch_token()
        return self._token["access_token"]


import sys
import os
from dotenv import load_dotenv
import logging
from typing import Optional, Any, Dict, List

load_dotenv(override=True)

sys.path.append('.')
from genai_gateway_tools.oauth import OAuthConfig, OAuthTokenFetcher
fromrtbc_security import enable_certs
from openai import OpenAI

logging.basicConfig(level=logging.INFO)

def _ensure_env_vars_for_oauth():
    required_env_vars = [
        "OAUTH_TOKEN_URL",
        "OAUTH_CLIENT_ID",
        "OAUTH_CLIENT_SECRET",
        "OAUTH_GRANT_TYPE",
        "OAUTH_SCOPE",
        "GW_BASE_URL",
    ]
    missing = [v for v in required_env_vars if not os.environ.get(v)]
    if missing:
        raise EnvironmentError(f"Missing required environment variables: {', '.join(missing)}")

# Lightweight cached token fetcher instance (uses genai_gateway_tools.oauth.OAuthTokenFetcher which does its own refresh)
_token_fetcher: Optional[OAuthTokenFetcher] = None

def _get_token_fetcher() -> OAuthTokenFetcher:
    global _token_fetcher
    if _token_fetcher is None:
        _ensure_env_vars_for_oauth()
        import os
        oauth_config = OAuthConfig(
            token_url=os.environ["OAUTH_TOKEN_URL"],
            client_id=os.environ["OAUTH_CLIENT_ID"],
            client_secret=os.environ["OAUTH_CLIENT_SECRET"],
            grant_type=os.environ["OAUTH_GRANT_TYPE"],
            scope=os.environ["OAUTH_SCOPE"],
        )
        _token_fetcher = OAuthTokenFetcher(oauth_config)
    return _token_fetcher

def get_access_token() -> str:
    """Return an OAuth access token string using the Gen AI Gateway OAuth helper.

    This wraps the genai_gateway_tools.OAuthTokenFetcher and is safe to call from other modules.
    """
    fetcher = _get_token_fetcher()
    token = fetcher.get_token()
    if isinstance(token, dict):
        return token.get("access_token") or token.get("token") or str(token)
    return str(token)

def create_client() -> OpenAI:
    """Create and return an OpenAI client configured with the current access token and gateway base URL."""
    token = get_access_token()
    base_url = os.environ.get("GM_BASE_URL")
    return OpenAI(api_key=token, base_url=base_url)

def send_chat_request(messages: List[Dict[str, Any]], model: str="gpt-4", **kwargs) -> Any:
    """
    Send a chat request (list of messages) to the AI model via the Gen AI Gateway client.
    Args:
        messages: List of message dicts in the OpenAI format [{"role": "user", "content": "..."}]
        model: Model name to call (defaults to gpt-4)
        **kwargs: Passed through to the underlying client.chat.completions.create call (e.g., temperature, max_tokens, response_format)
    Returns:
        The raw response object from the OpenAI SDK. Callers may inspect .choices[0].message.content.
    """
    client = create_client()
    response = client.chat.completions.create(model=model, messages=messages, **kwargs)
    return response

def send_gpt35_request(prompt: str) -> str:
    """Backward-compatible helper: send a single-user prompt to gpt-3.5-turbo and return the content string."""
    if not prompt or not isinstance(prompt, str):
        logging.error("Prompt must be a non-empty string.")
        raise ValueError("Prompt must be a non-empty string.")
    messages = [{"role": "user", "content": prompt}]
    response = send_chat_request(messages=messages, model="gpt-3.5-turbo")
    return response.choices[0].message.content

