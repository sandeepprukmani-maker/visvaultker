[privacy]
# CRITICAL: Disable all external data transmission
# Browser-use library sends telemetry and cloud sync data by default
# These settings are overridden by environment variables for security
# Set ANONYMIZED_TELEMETRY=false and BROWSER_USE_CLOUD_SYNC=false in .env
disable_telemetry = true
disable_cloud_sync = true

[browser]
headless = true
browser = chromium

[model_provider]
# AI Model Provider Configuration
# Supported providers: openai, anthropic, gemini, oauth_gateway
# - openai: Requires OPENAI_API_KEY environment variable
# - anthropic: Requires ANTHROPIC_API_KEY environment variable  
# - gemini: Requires GOOGLE_API_KEY environment variable
# - oauth_gateway: Requires OAuth credentials (OAUTH_TOKEN_URL, OAUTH_CLIENT_ID, etc.)
provider = oauth_gateway

# Model name - use provider-specific model names
# OpenAI examples: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo
# Anthropic examples: claude-3-5-sonnet-20241022, claude-3-5-haiku-20241022, claude-3-opus-20240229
# Gemini examples: gemini-2.0-flash-exp, gemini-1.5-pro, gemini-1.5-flash
# OAuth Gateway: Use your gateway's model name (e.g., gpt-4.1-2025-04-14-eastus-dz)
model = gpt-4o

# Request timeout in seconds
timeout = 90

# Temperature for model responses (0.0 - 1.0)
# Lower = more deterministic, Higher = more creative
temperature = 0.7

[openai]
# DEPRECATED: This section is kept for backward compatibility
# Please use [model_provider] section instead
# Use ChatBrowserUse optimized model (3-5x faster for browser automation)
# Set to true to use the specialized browser model, false for standard OpenAI models
use_chat_browser_use = false

[agent]
# Maximum steps the agent can take before stopping
# Increased to 60 for faster iteration through complex tasks
max_steps = 60

[logging]
# Minimal logging for maximum performance
# Disable detailed logging to reduce overhead
enable_detailed_logging = false

# Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
# WARNING level for minimal logging - only show issues
app_log_level = WARNING
browser_use_log_level = WARNING
agent_log_level = WARNING
llm_log_level = WARNING
playwright_log_level = ERROR

# Disable verbose LLM logging for speed
log_llm_requests = false
log_llm_responses = false

# Disable browser action logging for speed
log_browser_actions = false
log_page_state = false

# Disable performance/timing logs
log_performance = false

[browser_performance]
# Browser wait times - ULTRA FAST MODE
# Maximum speed - minimal wait times
# 80-90% faster than defaults
minimum_wait_page_load_time = 0.1
wait_for_network_idle_page_load_time = 0.3
wait_between_actions = 0.05

[advanced_features]
# Advanced browser automation features
# Disabled for maximum speed - enable only when needed
output_directory = .
enable_screenshots = false
enable_pdf_generation = false
enable_cookie_management = true
enable_state_persistence = true

[retry]
# Retry mechanism with exponential backoff
# Minimal retries for maximum speed
max_retries = 1
initial_delay = 0.2
max_delay = 5.0
backoff_factor = 2.0

[performance]
# Performance monitoring and metrics
track_detailed_metrics = true

[playwright_mcp]
# Playwright MCP Server Mode
# Options:
#   always_run - Keep MCP server running continuously (faster response, uses more resources)
#   on_demand - Start MCP server only when needed (saves resources, slower first request)
server_mode = always_run
# Timeout for on-demand server startup (seconds)
startup_timeout = 30
