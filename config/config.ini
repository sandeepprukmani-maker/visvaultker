[privacy]
# CRITICAL: Disable all external data transmission
# Browser-use library sends telemetry and cloud sync data by default
# These settings are overridden by environment variables for security
# Set ANONYMIZED_TELEMETRY=false and BROWSER_USE_CLOUD_SYNC=false in .env
disable_telemetry = true
disable_cloud_sync = true

[browser]
headless = false
browser = chromium

[model_provider]
# AI Model Provider Configuration
# Supported providers: openai, anthropic, gemini, oauth_gateway
# - openai: Requires OPENAI_API_KEY environment variable
# - anthropic: Requires ANTHROPIC_API_KEY environment variable  
# - gemini: Requires GOOGLE_API_KEY environment variable
# - oauth_gateway: Requires OAuth credentials (OAUTH_TOKEN_URL, OAUTH_CLIENT_ID, etc.)
provider = openai

# Model name - use provider-specific model names
# OpenAI examples: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo
# Anthropic examples: claude-3-5-sonnet-20241022, claude-3-5-haiku-20241022, claude-3-opus-20240229
# Gemini examples: gemini-2.0-flash-exp, gemini-1.5-pro, gemini-1.5-flash
# OAuth Gateway: Use your gateway's model name (e.g., gpt-4.1-2025-04-14-eastus-dz)
model = gpt-4o

# Request timeout in seconds
timeout = 90

# Temperature for model responses (0.0 - 1.0)
# Lower = more deterministic, Higher = more creative
temperature = 0.7

[openai]
# DEPRECATED: This section is kept for backward compatibility
# Please use [model_provider] section instead
# Use ChatBrowserUse optimized model (3-5x faster for browser automation)
# Set to true to use the specialized browser model, false for standard OpenAI models
use_chat_browser_use = false

[agent]
# Maximum steps the agent can take before stopping
# Increased to 60 for faster iteration through complex tasks
max_steps = 60

[logging]
# Detailed logging configuration for debugging
# Enable this to see exactly what's happening during automation
enable_detailed_logging = true

# Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
# DEBUG - Most verbose, shows all internal operations
# INFO - Standard logging, shows major steps
# WARNING - Only warnings and errors
# ERROR - Only errors
# CRITICAL - Only critical failures
app_log_level = INFO
browser_use_log_level = INFO
agent_log_level = INFO
llm_log_level = INFO
playwright_log_level = WARNING

# Enable request/response logging for LLM calls
log_llm_requests = true
log_llm_responses = true

# Enable browser action logging
log_browser_actions = true
log_page_state = true

# Enable performance/timing logs
log_performance = true

[browser_performance]
# Browser wait times - BALANCED FAST MODE
# Optimized for fast execution while maintaining reliability
# 50-70% faster than defaults while preserving stability
minimum_wait_page_load_time = 0.3
wait_for_network_idle_page_load_time = 0.6
wait_between_actions = 0.2

[advanced_features]
# Advanced browser automation features
# Screenshots will be saved to screenshots/ folder for easy UI access
# Using "." as base directory so screenshots go to ./screenshots/
output_directory = .
enable_screenshots = true
enable_pdf_generation = true
enable_cookie_management = true
enable_state_persistence = true

[retry]
# Retry mechanism with exponential backoff
# Balanced for speed and reliability
max_retries = 2
initial_delay = 0.5
max_delay = 10.0
backoff_factor = 2.0

[performance]
# Performance monitoring and metrics
track_detailed_metrics = true

[playwright_mcp]
# Playwright MCP Server Mode
# Options:
#   always_run - Keep MCP server running continuously (faster response, uses more resources)
#   on_demand - Start MCP server only when needed (saves resources, slower first request)
server_mode = always_run
# Timeout for on-demand server startup (seconds)
startup_timeout = 30
