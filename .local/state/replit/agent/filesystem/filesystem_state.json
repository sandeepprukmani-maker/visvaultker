{"file_contents":{"config.py":{"content":"import os\nfrom typing import Literal\n\nModelType = Literal[\"claude\", \"gpt4o\", \"gemini\"]\n\nANTHROPIC_API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\", \"\")\nOPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\", \"\")\nGEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\", \"\")\n\nMODEL_CONFIGS = {\n    \"claude\": {\n        \"name\": \"claude-sonnet-4-20250514\",\n        \"api_key\": ANTHROPIC_API_KEY,\n        \"display_name\": \"Claude 4 Sonnet (Recommended)\"\n    },\n    \"gpt4o\": {\n        \"name\": \"gpt-4o\",\n        \"api_key\": OPENAI_API_KEY,\n        \"display_name\": \"GPT-4o\"\n    },\n    \"gemini\": {\n        \"name\": \"gemini-2.0-flash-exp\",\n        \"api_key\": GEMINI_API_KEY,\n        \"display_name\": \"Gemini 2.0 Flash\"\n    }\n}\n\nMCP_SERVER_COMMAND = \"npx\"\nMCP_SERVER_ARGS = [\"@playwright/mcp\"]\n\nOUTPUT_DIR = \"generated_scripts\"\nTRACE_DIR = \"traces\"\nMAX_HEALING_ATTEMPTS = 3\n\nEXECUTOR_SYSTEM_PROMPT = \"\"\"You are a browser automation expert. Your task is to perform web automation using Playwright MCP tools.\n\nAvailable MCP tools:\n- playwright_navigate: Navigate to a URL\n- playwright_click: Click on an element\n- playwright_fill: Fill a form field\n- playwright_screenshot: Take a screenshot\n- playwright_evaluate: Execute JavaScript\n\nWhen performing tasks:\n1. Use accessible selectors (role, label, placeholder, test-id) when possible\n2. Navigate step by step\n3. Verify actions were successful\n4. Be precise with selectors\n\nDescribe each action clearly as you perform it.\"\"\"\n\nCODE_GENERATOR_SYSTEM_PROMPT = \"\"\"You are a Python code generation expert. Convert browser automation execution traces into clean, reusable Playwright Python scripts.\n\nRequirements:\n1. Use async/await patterns properly\n2. Prioritize intelligent locators in this order:\n   - page.get_by_role()\n   - page.get_by_label()\n   - page.get_by_placeholder()\n   - page.get_by_test_id()\n   - page.locator() (CSS) only as last resort\n3. Include proper imports\n4. Use descriptive variable names\n5. Add comments for clarity\n6. Create a single, executable Python function\n7. Handle errors gracefully\n8. Structure code cleanly with proper spacing\n\nGenerate ONLY the Python code, no explanations.\"\"\"\n\nHEALER_SYSTEM_PROMPT = \"\"\"You are a code debugging expert. Analyze failed Playwright scripts and trace files to fix broken locators.\n\nWhen healing:\n1. Identify why the original locator failed from the trace\n2. Suggest better, more robust locators\n3. Use accessible selectors (role, label, placeholder) over CSS\n4. Consider dynamic content and timing issues\n5. Output the fixed Python code\n\nGenerate ONLY the fixed Python code, no explanations.\"\"\"\n","size_bytes":2572},"agents.py":{"content":"import json\nimport os\nfrom typing import Any, Dict, List, Optional, Union\nfrom anthropic import Anthropic\nfrom openai import OpenAI\ntry:\n    import google.generativeai as genai\n    GEMINI_AVAILABLE = True\nexcept ImportError:\n    GEMINI_AVAILABLE = False\n    genai = None\n\nfrom rich.console import Console\nfrom config import (\n    MODEL_CONFIGS, ModelType, EXECUTOR_SYSTEM_PROMPT,\n    CODE_GENERATOR_SYSTEM_PROMPT, HEALER_SYSTEM_PROMPT\n)\nfrom mcp_client import PlaywrightMCPClient\n\nconsole = Console()\n\n\nclass ExecutorAgent:\n    def __init__(self, model: ModelType, mcp_client: PlaywrightMCPClient):\n        self.model = model\n        self.mcp_client = mcp_client\n        self.execution_trace: List[Dict[str, Any]] = []\n        self.model_config = MODEL_CONFIGS[model]\n        self.client: Union[Anthropic, OpenAI, Any] = None\n        \n        if model == \"claude\":\n            self.client = Anthropic(api_key=self.model_config[\"api_key\"])\n        elif model == \"gpt4o\":\n            self.client = OpenAI(api_key=self.model_config[\"api_key\"])\n        elif model == \"gemini\":\n            if GEMINI_AVAILABLE and genai:\n                genai.configure(api_key=self.model_config[\"api_key\"])\n                self.client = genai.GenerativeModel(self.model_config[\"name\"])\n    \n    async def execute_task(self, task_description: str) -> Dict[str, Any]:\n        console.print(f\"\\n[bold magenta]ğŸ¤– Executor Agent starting...[/bold magenta]\")\n        console.print(f\"[magenta]Model: {self.model_config['display_name']}[/magenta]\")\n        console.print(f\"[magenta]Task: {task_description}[/magenta]\\n\")\n        \n        self.execution_trace = []\n        \n        tools_description = self.mcp_client.get_tools_description()\n        \n        prompt = f\"\"\"Task: {task_description}\n\nAvailable Playwright MCP tools:\n{tools_description}\n\nExecute this task step by step using the available tools. After each action, describe what you did and what you observe.\n\nStart by navigating to the appropriate website and proceed with the automation.\"\"\"\n        \n        if self.model == \"claude\":\n            result = await self._execute_with_claude(prompt)\n        elif self.model == \"gpt4o\":\n            result = await self._execute_with_gpt4o(prompt)\n        elif self.model == \"gemini\":\n            result = await self._execute_with_gemini(prompt)\n        else:\n            result = {\n                \"success\": False,\n                \"trace\": [],\n                \"model\": self.model,\n                \"error\": \"Unknown model\"\n            }\n        \n        return result\n    \n    async def _execute_with_claude(self, prompt: str) -> Dict[str, Any]:\n        if not isinstance(self.client, Anthropic):\n            raise RuntimeError(\"Claude client not properly initialized\")\n            \n        mcp_tools = []\n        for tool in self.mcp_client.tools:\n            mcp_tools.append({\n                \"name\": tool[\"name\"],\n                \"description\": tool.get(\"description\", \"\"),\n                \"input_schema\": tool.get(\"inputSchema\", {})\n            })\n        \n        messages: List[Dict[str, Any]] = [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]}]\n        max_iterations = 20\n        \n        for iteration in range(max_iterations):\n            response = self.client.messages.create(\n                model=self.model_config[\"name\"],\n                max_tokens=4096,\n                system=EXECUTOR_SYSTEM_PROMPT,\n                messages=messages,\n                tools=mcp_tools\n            )\n            \n            messages.append({\n                \"role\": \"assistant\",\n                \"content\": response.content\n            })\n            \n            if response.stop_reason == \"end_turn\":\n                console.print(\"[green]âœ“ Task execution completed[/green]\")\n                break\n            \n            if response.stop_reason == \"tool_use\":\n                tool_results = []\n                \n                for block in response.content:\n                    if block.type == \"tool_use\":\n                        tool_name = block.name\n                        tool_input = block.input\n                        \n                        self.execution_trace.append({\n                            \"type\": \"tool_call\",\n                            \"tool\": tool_name,\n                            \"arguments\": tool_input\n                        })\n                        \n                        result = await self.mcp_client.call_tool(tool_name, tool_input)\n                        \n                        result_content = []\n                        for content_item in result.content:\n                            if hasattr(content_item, 'text'):\n                                result_content.append(content_item.text)\n                        \n                        result_text = \"\\n\".join(result_content)\n                        \n                        self.execution_trace.append({\n                            \"type\": \"tool_result\",\n                            \"tool\": tool_name,\n                            \"result\": result_text\n                        })\n                        \n                        tool_results.append({\n                            \"type\": \"tool_result\",\n                            \"tool_use_id\": block.id,\n                            \"content\": [{\"type\": \"text\", \"text\": result_text}]\n                        })\n                \n                messages.append({\n                    \"role\": \"user\",\n                    \"content\": tool_results\n                })\n        \n        return {\n            \"success\": True,\n            \"trace\": self.execution_trace,\n            \"model\": self.model\n        }\n    \n    async def _execute_with_gpt4o(self, prompt: str) -> Dict[str, Any]:\n        if not isinstance(self.client, OpenAI):\n            raise RuntimeError(\"OpenAI client not properly initialized\")\n            \n        tools = []\n        for tool in self.mcp_client.tools:\n            tools.append({\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": tool[\"name\"],\n                    \"description\": tool.get(\"description\", \"\"),\n                    \"parameters\": tool.get(\"inputSchema\", {})\n                }\n            })\n        \n        messages: List[Dict[str, Any]] = [\n            {\"role\": \"system\", \"content\": EXECUTOR_SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n        \n        max_iterations = 20\n        \n        for iteration in range(max_iterations):\n            response = self.client.chat.completions.create(\n                model=self.model_config[\"name\"],\n                messages=messages,\n                tools=tools\n            )\n            \n            message = response.choices[0].message\n            messages.append({\n                \"role\": \"assistant\",\n                \"content\": message.content or \"\",\n                \"tool_calls\": message.tool_calls\n            })\n            \n            if not message.tool_calls:\n                console.print(\"[green]âœ“ Task execution completed[/green]\")\n                break\n            \n            for tool_call in message.tool_calls:\n                tool_name = tool_call.function.name\n                tool_args = json.loads(tool_call.function.arguments)\n                \n                self.execution_trace.append({\n                    \"type\": \"tool_call\",\n                    \"tool\": tool_name,\n                    \"arguments\": tool_args\n                })\n                \n                result = await self.mcp_client.call_tool(tool_name, tool_args)\n                \n                result_content = []\n                for content_item in result.content:\n                    if hasattr(content_item, 'text'):\n                        result_content.append(content_item.text)\n                \n                result_text = \"\\n\".join(result_content)\n                \n                self.execution_trace.append({\n                    \"type\": \"tool_result\",\n                    \"tool\": tool_name,\n                    \"result\": result_text\n                })\n                \n                messages.append({\n                    \"role\": \"tool\",\n                    \"tool_call_id\": tool_call.id,\n                    \"content\": result_text\n                })\n        \n        return {\n            \"success\": True,\n            \"trace\": self.execution_trace,\n            \"model\": self.model\n        }\n    \n    async def _execute_with_gemini(self, prompt: str) -> Dict[str, Any]:\n        console.print(\"[yellow]Note: Gemini does not support MCP tool calling natively. Using Claude for execution.[/yellow]\")\n        console.print(\"[yellow]Switching to Claude...[/yellow]\")\n        \n        claude_agent = ExecutorAgent(\"claude\", self.mcp_client)\n        return await claude_agent.execute_task(prompt.split(\"Task: \")[1].split(\"\\n\")[0])\n\n\nclass CodeGeneratorAgent:\n    def __init__(self, model: ModelType):\n        self.model = model\n        self.model_config = MODEL_CONFIGS[model]\n        self.client: Union[Anthropic, OpenAI, Any] = None\n        \n        if model == \"claude\":\n            self.client = Anthropic(api_key=self.model_config[\"api_key\"])\n        elif model == \"gpt4o\":\n            self.client = OpenAI(api_key=self.model_config[\"api_key\"])\n        elif model == \"gemini\":\n            if GEMINI_AVAILABLE and genai:\n                genai.configure(api_key=self.model_config[\"api_key\"])\n                self.client = genai.GenerativeModel(self.model_config[\"name\"])\n    \n    async def generate_code(self, execution_trace: List[Dict[str, Any]], task_description: str) -> str:\n        console.print(f\"\\n[bold blue]ğŸ“ Code Generator Agent starting...[/bold blue]\")\n        console.print(f\"[blue]Model: {self.model_config['display_name']}[/blue]\\n\")\n        \n        trace_text = json.dumps(execution_trace, indent=2)\n        \n        prompt = f\"\"\"Task Description: {task_description}\n\nExecution Trace:\n{trace_text}\n\nGenerate a clean, production-ready Python Playwright script that performs this automation task.\n\nUse intelligent locators:\n1. page.get_by_role() - for buttons, links, headings, etc.\n2. page.get_by_label() - for form fields with labels\n3. page.get_by_placeholder() - for inputs with placeholders\n4. page.get_by_test_id() - for elements with test IDs\n5. page.locator() - only as last resort for CSS selectors\n\nInclude:\n- Proper async/await structure\n- All necessary imports\n- Error handling\n- Descriptive variable names\n- Comments where helpful\n\nOutput ONLY the Python code, starting with imports.\"\"\"\n        \n        code = \"\"\n        if self.model == \"claude\":\n            code = await self._generate_with_claude(prompt)\n        elif self.model == \"gpt4o\":\n            code = await self._generate_with_gpt4o(prompt)\n        elif self.model == \"gemini\":\n            code = await self._generate_with_gemini(prompt)\n        \n        code = self._clean_code(code)\n        \n        console.print(\"[green]âœ“ Code generation completed[/green]\")\n        return code\n    \n    async def _generate_with_claude(self, prompt: str) -> str:\n        if not isinstance(self.client, Anthropic):\n            raise RuntimeError(\"Claude client not properly initialized\")\n            \n        response = self.client.messages.create(\n            model=self.model_config[\"name\"],\n            max_tokens=4096,\n            system=CODE_GENERATOR_SYSTEM_PROMPT,\n            messages=[{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]}]\n        )\n        \n        for block in response.content:\n            if hasattr(block, 'text'):\n                return block.text\n        \n        return \"\"\n    \n    async def _generate_with_gpt4o(self, prompt: str) -> str:\n        if not isinstance(self.client, OpenAI):\n            raise RuntimeError(\"OpenAI client not properly initialized\")\n            \n        response = self.client.chat.completions.create(\n            model=self.model_config[\"name\"],\n            messages=[\n                {\"role\": \"system\", \"content\": CODE_GENERATOR_SYSTEM_PROMPT},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n        )\n        \n        return response.choices[0].message.content or \"\"\n    \n    async def _generate_with_gemini(self, prompt: str) -> str:\n        if not GEMINI_AVAILABLE or not genai or not self.client:\n            raise RuntimeError(\"Gemini client not properly initialized\")\n            \n        full_prompt = f\"{CODE_GENERATOR_SYSTEM_PROMPT}\\n\\n{prompt}\"\n        response = self.client.generate_content(full_prompt)\n        return response.text if hasattr(response, 'text') else \"\"\n    \n    def _clean_code(self, code: str) -> str:\n        code = code.strip()\n        \n        if code.startswith(\"```python\"):\n            code = code[9:]\n        elif code.startswith(\"```\"):\n            code = code[3:]\n        \n        if code.endswith(\"```\"):\n            code = code[:-3]\n        \n        return code.strip()\n\n\nclass HealerAgent:\n    def __init__(self, model: ModelType):\n        self.model = model\n        self.model_config = MODEL_CONFIGS[model]\n        self.client: Union[Anthropic, OpenAI, Any] = None\n        \n        if model == \"claude\":\n            self.client = Anthropic(api_key=self.model_config[\"api_key\"])\n        elif model == \"gpt4o\":\n            self.client = OpenAI(api_key=self.model_config[\"api_key\"])\n        elif model == \"gemini\":\n            if GEMINI_AVAILABLE and genai:\n                genai.configure(api_key=self.model_config[\"api_key\"])\n                self.client = genai.GenerativeModel(self.model_config[\"name\"])\n    \n    async def heal_code(self, original_code: str, error_message: str, trace_file: Optional[str] = None) -> str:\n        console.print(f\"\\n[bold red]ğŸ”§ Healer Agent starting...[/bold red]\")\n        console.print(f\"[red]Model: {self.model_config['display_name']}[/red]\\n\")\n        \n        trace_info = \"\"\n        if trace_file and os.path.exists(trace_file):\n            trace_info = f\"\\n\\nPlaywright trace file available at: {trace_file}\"\n        \n        prompt = f\"\"\"The following Playwright script failed with an error:\n\nORIGINAL CODE:\n{original_code}\n\nERROR:\n{error_message}\n{trace_info}\n\nAnalyze the error and fix the script. Common issues:\n1. Incorrect selectors - use more robust locators\n2. Timing issues - add proper waits\n3. Element not found - verify element exists before interacting\n4. Use intelligent locators (get_by_role, get_by_label, etc.) instead of CSS\n\nOutput ONLY the fixed Python code, no explanations.\"\"\"\n        \n        code = \"\"\n        if self.model == \"claude\":\n            code = await self._heal_with_claude(prompt)\n        elif self.model == \"gpt4o\":\n            code = await self._heal_with_gpt4o(prompt)\n        elif self.model == \"gemini\":\n            code = await self._heal_with_gemini(prompt)\n        \n        code = self._clean_code(code)\n        \n        console.print(\"[green]âœ“ Code healing completed[/green]\")\n        return code\n    \n    async def _heal_with_claude(self, prompt: str) -> str:\n        if not isinstance(self.client, Anthropic):\n            raise RuntimeError(\"Claude client not properly initialized\")\n            \n        response = self.client.messages.create(\n            model=self.model_config[\"name\"],\n            max_tokens=4096,\n            system=HEALER_SYSTEM_PROMPT,\n            messages=[{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]}]\n        )\n        \n        for block in response.content:\n            if hasattr(block, 'text'):\n                return block.text\n        \n        return \"\"\n    \n    async def _heal_with_gpt4o(self, prompt: str) -> str:\n        if not isinstance(self.client, OpenAI):\n            raise RuntimeError(\"OpenAI client not properly initialized\")\n            \n        response = self.client.chat.completions.create(\n            model=self.model_config[\"name\"],\n            messages=[\n                {\"role\": \"system\", \"content\": HEALER_SYSTEM_PROMPT},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n        )\n        \n        return response.choices[0].message.content or \"\"\n    \n    async def _heal_with_gemini(self, prompt: str) -> str:\n        if not GEMINI_AVAILABLE or not genai or not self.client:\n            raise RuntimeError(\"Gemini client not properly initialized\")\n            \n        full_prompt = f\"{HEALER_SYSTEM_PROMPT}\\n\\n{prompt}\"\n        response = self.client.generate_content(full_prompt)\n        return response.text if hasattr(response, 'text') else \"\"\n    \n    def _clean_code(self, code: str) -> str:\n        code = code.strip()\n        \n        if code.startswith(\"```python\"):\n            code = code[9:]\n        elif code.startswith(\"```\"):\n            code = code[3:]\n        \n        if code.endswith(\"```\"):\n            code = code[:-3]\n        \n        return code.strip()\n","size_bytes":16777},"replit.md":{"content":"# Playwright MCP Automation Script Generator\n\n## Overview\n\nThis project converts natural language descriptions into executable Python Playwright automation scripts. It uses a multi-agent AI system (supporting Claude, GPT-4o, or Gemini) to perform live browser automation, observe the interactions, and then generate reusable Python scripts from those execution traces. The system includes optional self-healing capabilities to fix failing scripts automatically.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## System Architecture\n\n### Multi-Agent Design Pattern\n\n**Problem**: Converting natural language to reliable, reusable browser automation requires both understanding user intent and generating correct code.\n\n**Solution**: Three specialized agents with distinct responsibilities:\n- **Executor Agent**: Performs live browser automation using Playwright MCP tools, creating an execution trace\n- **Code Generator Agent**: Transforms execution traces into standalone, rerunnable Python scripts\n- **Healer Agent**: Analyzes script failures and automatically fixes issues (optional, enabled by default)\n\n**Rationale**: This separation allows the system to learn from actual browser interactions rather than blindly generating code. The Executor Agent explores the real browser environment, the Code Generator Agent codifies those successful interactions, and the Healer Agent provides robustness through automatic error recovery.\n\n**Pros**: More reliable script generation based on actual browser behavior; clear separation of concerns\n**Cons**: Additional complexity compared to direct code generation; requires live browser execution\n\n### Multi-Provider AI Model Support\n\n**Problem**: Different users have access to different AI providers (Anthropic, OpenAI, Google), each with distinct APIs and capabilities.\n\n**Solution**: Unified model abstraction layer in `config.py` with a `ModelType` literal type and standardized configuration dictionary. Each agent dynamically initializes the appropriate client based on model selection.\n\n**Implementation**:\n- Standardized model configuration with API keys, model names, and display names\n- Provider-specific client initialization within agent constructors\n- Graceful degradation for optional dependencies (Gemini SDK)\n\n**Alternatives Considered**: LangChain or similar abstraction frameworks, but opted for direct SDK usage for simplicity and fine-grained control.\n\n### MCP (Model Context Protocol) Integration\n\n**Problem**: AI agents need a standardized way to control browser automation tools.\n\n**Solution**: Custom `PlaywrightMCPClient` wrapper that:\n- Manages stdio-based communication with the Playwright MCP server (Node.js process)\n- Exposes browser automation capabilities (navigate, click, fill, screenshot, evaluate) as structured tool descriptions\n- Handles tool execution requests and formats results for AI consumption\n\n**Architecture Decision**: The MCP server runs as an external Node.js process (`npx @playwright/mcp`) communicating via stdio. This keeps the Python codebase lightweight while leveraging the official Playwright MCP implementation.\n\n**Pros**: Standard protocol for tool usage; separation of concerns between Python agents and browser automation\n**Cons**: Requires Node.js runtime; adds process management complexity\n\n### Execution Trace System\n\n**Problem**: Need to capture and replay browser automation sequences reliably.\n\n**Solution**: The Executor Agent maintains an execution trace (list of dictionaries) recording each action, tool used, parameters, and results. This trace serves as the input for the Code Generator Agent.\n\n**Rationale**: Traces provide a structured, complete record of successful automation sequences, making code generation more accurate than trying to generate code directly from natural language.\n\n### File Organization and Output Management\n\n**Problem**: Generated scripts and execution traces need organized storage.\n\n**Solution**: \n- `OUTPUT_DIR` (default: \"generated_scripts\"): Stores generated Python Playwright scripts\n- `TRACE_DIR` (default: \"traces\"): Stores JSON execution traces\n- Auto-generated filenames or user-specified output paths via CLI\n\n**Design Decision**: Separate directories for scripts vs. traces allows easy inspection of both the final output and the intermediate execution history.\n\n## External Dependencies\n\n### AI Model APIs\n\n- **Anthropic Claude API**: Primary recommended model (Claude 4 Sonnet), accessed via `anthropic` Python SDK\n- **OpenAI API**: GPT-4o support via `openai` Python SDK  \n- **Google Gemini API**: Gemini 2.0 Flash support via `google-generativeai` SDK (optional dependency)\n\nConfiguration: API keys provided via environment variables (`ANTHROPIC_API_KEY`, `OPENAI_API_KEY`, `GEMINI_API_KEY`)\n\n### Browser Automation Stack\n\n- **Playwright**: Python browser automation library (v1.55.0)\n- **Playwright MCP Server**: Node.js package (`@playwright/mcp`) that exposes Playwright functionality via Model Context Protocol\n- **Chromium Browser**: Playwright-managed browser for automation execution\n\nInstallation requires both Python package (`playwright`) and system browser (`playwright install chromium`)\n\n### Model Context Protocol (MCP)\n\n- **MCP Python SDK**: Client library (v1.20.0) for communicating with MCP servers via stdio\n- Protocol enables standardized AI-to-tool communication\n\n### User Interface\n\n- **Rich**: Terminal UI library for formatted console output, syntax highlighting, and progress display\n\n### Runtime Requirements\n\n- **Python 3.11+**: Required for modern type hints and async features\n- **Node.js 20+**: Required for Playwright MCP server execution","size_bytes":5663},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"anthropic>=0.72.0\",\n    \"google-genai>=1.49.0\",\n    \"mcp>=1.20.0\",\n    \"openai>=2.7.1\",\n    \"playwright>=1.55.0\",\n    \"rich>=14.2.0\",\n]\n","size_bytes":283},"read_me.md":{"content":"# Playwright MCP Automation Script Generator\n\n## Overview\n\nThis project is a natural language to Playwright automation script generator. It uses AI models (Claude, GPT-4o, or Gemini) to convert plain English task descriptions into executable Python Playwright scripts through the Model Context Protocol (MCP). The system employs a multi-agent architecture where an Executor Agent performs browser automation tasks, a Code Generator Agent translates execution traces into reusable scripts, and a Healer Agent attempts to fix failed scripts automatically.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## System Architecture\n\n### Multi-Agent Architecture\n\n**Problem**: Need to convert natural language to reliable, reusable browser automation scripts.\n\n**Solution**: Three-agent system with distinct responsibilities:\n- **Executor Agent**: Performs live browser automation using Playwright MCP tools\n- **Code Generator Agent**: Converts execution traces into standalone Python scripts\n- **Healer Agent**: Analyzes and fixes failing scripts (optional, enabled by default)\n\n**Rationale**: Separating execution from code generation allows the system to learn from actual browser interactions rather than generating code blindly. The healing layer adds robustness by automatically recovering from common automation failures.\n\n### Model Abstraction Layer\n\n**Problem**: Support multiple AI providers (Anthropic, OpenAI, Google) with different APIs.\n\n**Solution**: Unified `ModelType` configuration system in `config.py` with provider-specific client initialization in agent classes.\n\n**Implementation Details**:\n- Each model has standardized configuration including name, API key, and display name\n- Agents dynamically instantiate the appropriate client based on model selection\n- Gemini integration is optional (graceful degradation if SDK unavailable)\n\n**Alternatives Considered**: Could have used LangChain or similar abstraction, but opted for direct SDK usage for simplicity and control.\n\n### MCP Integration Pattern\n\n**Problem**: Enable AI agents to control browser automation tools through a standard protocol.\n\n**Solution**: Playwright MCP client wrapper (`PlaywrightMCPClient`) that:\n- Manages stdio-based communication with the Playwright MCP server\n- Exposes browser automation capabilities as tool descriptions for AI consumption\n- Handles tool execution and result formatting\n\n**Key Design Decision**: The MCP server runs as an external Node.js process (`npx @playwright/mcp`), communicating via stdio. This keeps the Python codebase lightweight while leveraging the full Playwright ecosystem.\n\n### Execution Trace System\n\n**Problem**: Bridge the gap between interactive automation and script generation.\n\n**Solution**: The Executor Agent maintains a detailed execution trace as it performs tasks. Each action (navigate, click, fill, etc.) is logged with parameters and results. This trace becomes the primary input for the Code Generator Agent.\n\n**Benefits**:\n- Provides concrete examples of working automation sequences\n- Enables the Code Generator to produce accurate, tested scripts\n- Allows the Healer to understand what was originally intended\n\n### Configuration Management\n\n**Problem**: Handle API keys, model selection, and runtime parameters securely.\n\n**Solution**: Environment-based configuration through `config.py`:\n- API keys loaded from environment variables\n- Model configurations centralized with clear defaults\n- Filesystem paths (output directories, trace storage) defined as constants\n\n**Security Consideration**: API keys never hardcoded; must be provided via environment variables.\n\n### Output Management\n\n**Problem**: Organize generated scripts and execution traces for reusability and debugging.\n\n**Solution**: \n- Generated scripts saved to `OUTPUT_DIR` (default: `generated_scripts/`)\n- Execution traces saved to `TRACE_DIR` for analysis\n- Auto-generated filenames with timestamps for uniqueness\n- Rich console output for real-time progress visualization\n\n### Error Recovery Architecture\n\n**Problem**: Generated scripts may fail due to selector issues, timing problems, or site changes.\n\n**Solution**: Optional auto-healing system (controllable via `--no-heal` flag):\n- Healer Agent analyzes failure traces and error messages\n- Attempts to fix common issues (up to `MAX_HEALING_ATTEMPTS` times)\n- Uses AI to reason about failures and propose corrections\n\n**Pros**: Significantly improves success rate for generated scripts\n**Cons**: Adds execution time; may mask underlying design issues\n\n## External Dependencies\n\n### AI Model Providers\n\n- **Anthropic Claude**: Primary recommended model (`claude-sonnet-4-20250514`)\n- **OpenAI GPT-4o**: Alternative model option\n- **Google Gemini**: Alternative model option (`gemini-2.0-flash-exp`)\n\nAll require API keys configured via environment variables.\n\n### Model Context Protocol (MCP)\n\n- **Playwright MCP Server**: Node.js-based server (`@playwright/mcp` npm package)\n- **MCP Python SDK**: Client library for MCP communication (`mcp` package)\n- Provides standardized browser automation tool interface\n\n### UI and Output\n\n- **Rich**: Terminal UI library for formatted console output, syntax highlighting, and progress visualization\n\n### Browser Automation\n\n- **Playwright**: (Indirect) The MCP server wraps Playwright, providing browser automation capabilities without direct Python SDK dependency\n\n### Python Standard Library\n\n- `asyncio`: Async/await pattern for MCP communication and agent coordination\n- `argparse`: CLI argument parsing\n- `json`: Data serialization for traces and tool descriptions\n- `pathlib`: Cross-platform filesystem operations","size_bytes":5660},"example.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nExample usage of the Playwright MCP Automation Script Generator\n\nThis script demonstrates how to use the CLI tool to generate automation scripts.\n\"\"\"\n\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.markdown import Markdown\n\nconsole = Console()\n\nEXAMPLES = \"\"\"\n# Playwright MCP Automation Script Generator\n\n## Quick Start Examples\n\n### Basic Usage\n```bash\npython main.py \"Navigate to example.com and click the login button\"\n```\n\n### Choose a different AI model\n```bash\npython main.py \"Fill out the contact form\" --model gpt4o\npython main.py \"Search for Python tutorials\" --model gemini\n```\n\n### Custom output file\n```bash\npython main.py \"Click the submit button\" --output my_script.py\n```\n\n### Disable auto-healing\n```bash\npython main.py \"Navigate to site\" --no-heal\n```\n\n## Sample Tasks\n\n### E-commerce\n```bash\npython main.py \"Go to amazon.com, search for laptop, and add first result to cart\"\n```\n\n### Form Filling\n```bash\npython main.py \"Navigate to example.com/contact and fill out the contact form\"\n```\n\n### Web Scraping\n```bash\npython main.py \"Go to news.ycombinator.com and get the top 5 story titles\"\n```\n\n### Testing\n```bash\npython main.py \"Login to the app with test credentials and verify dashboard loads\"\n```\n\n## Available Models\n\n- **claude** (default) - Claude 4 Sonnet - Recommended for best results\n- **gpt4o** - GPT-4o - Fast and capable\n- **gemini** - Gemini 2.0 Flash - Google's latest\n\n## Before You Start\n\nMake sure you have set up your API keys:\n- ANTHROPIC_API_KEY (for Claude)\n- OPENAI_API_KEY (for GPT-4o)\n- GEMINI_API_KEY (for Gemini)\n\n## How It Works\n\n1. ğŸ¤– **Executor Agent** performs your task live in a browser using MCP\n2. ğŸ“ **Code Generator** creates a clean Python script from the execution\n3. ğŸ”§ **Auto-Healer** fixes any issues if the script fails (optional)\n\nYour generated scripts will be saved in the `generated_scripts/` directory.\n\"\"\"\n\nconsole.print(Panel.fit(\n    \"[bold cyan]Playwright MCP Automation Script Generator[/bold cyan]\",\n    border_style=\"cyan\"\n))\n\nmd = Markdown(EXAMPLES)\nconsole.print(md)\n\nconsole.print(\"\\n[bold yellow]Ready to generate automation scripts![/bold yellow]\")\nconsole.print(\"[dim]Run this tool with: python main.py \\\"your task description\\\"[/dim]\\n\")\n","size_bytes":2278},"mcp_client.py":{"content":"import asyncio\nimport json\nimport subprocess\nfrom typing import Any, Dict, List, Optional\nfrom mcp import ClientSession, StdioServerParameters\nfrom mcp.client.stdio import stdio_client\nfrom rich.console import Console\n\nconsole = Console()\n\n\nclass PlaywrightMCPClient:\n    def __init__(self, command: str, args: List[str]):\n        self.command = command\n        self.args = args\n        self.session: Optional[ClientSession] = None\n        self.read = None\n        self.write = None\n        self.tools: List[Dict[str, Any]] = []\n        \n    async def __aenter__(self):\n        await self.connect()\n        return self\n        \n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        await self.disconnect()\n        \n    async def connect(self):\n        console.print(\"[cyan]Starting Playwright MCP server...[/cyan]\")\n        \n        server_params = StdioServerParameters(\n            command=self.command,\n            args=self.args,\n            env=None\n        )\n        \n        stdio_context = stdio_client(server_params)\n        self.read, self.write = await stdio_context.__aenter__()\n        self.session = ClientSession(self.read, self.write)\n        \n        await self.session.__aenter__()\n        await self.session.initialize()\n        \n        tools_list = await self.session.list_tools()\n        self.tools = [tool.model_dump() for tool in tools_list.tools]\n        \n        console.print(f\"[green]âœ“ MCP server connected. Available tools: {len(self.tools)}[/green]\")\n        \n        return self\n    \n    async def disconnect(self):\n        if self.session:\n            await self.session.__aexit__(None, None, None)\n            console.print(\"[cyan]MCP server disconnected[/cyan]\")\n    \n    async def call_tool(self, tool_name: str, arguments: Dict[str, Any]) -> Any:\n        if not self.session:\n            raise RuntimeError(\"MCP client not connected\")\n        \n        console.print(f\"[yellow]â†’ Calling tool: {tool_name}[/yellow]\")\n        console.print(f\"[dim]  Arguments: {json.dumps(arguments, indent=2)}[/dim]\")\n        \n        result = await self.session.call_tool(tool_name, arguments)\n        \n        console.print(f\"[green]âœ“ Tool executed: {tool_name}[/green]\")\n        \n        return result\n    \n    def get_tools_description(self) -> str:\n        if not self.tools:\n            return \"No tools available\"\n        \n        descriptions = []\n        for tool in self.tools:\n            tool_desc = f\"- {tool['name']}: {tool.get('description', 'No description')}\"\n            if 'inputSchema' in tool:\n                props = tool['inputSchema'].get('properties', {})\n                if props:\n                    params = \", \".join(props.keys())\n                    tool_desc += f\"\\n  Parameters: {params}\"\n            descriptions.append(tool_desc)\n        \n        return \"\\n\".join(descriptions)\n","size_bytes":2847},"main.py":{"content":"#!/usr/bin/env python3\nimport asyncio\nimport argparse\nimport os\nimport sys\nimport json\nfrom datetime import datetime\nfrom pathlib import Path\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.syntax import Syntax\n\nfrom config import MODEL_CONFIGS, ModelType, MCP_SERVER_COMMAND, MCP_SERVER_ARGS, OUTPUT_DIR, TRACE_DIR\nfrom mcp_client import PlaywrightMCPClient\nfrom agents import ExecutorAgent, CodeGeneratorAgent, HealerAgent\n\nconsole = Console()\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(\n        description=\"Convert natural language to rerunnable Python Playwright scripts using MCP\"\n    )\n    \n    parser.add_argument(\n        \"task\",\n        help=\"Natural language description of the automation task\"\n    )\n    \n    parser.add_argument(\n        \"--model\",\n        type=str,\n        choices=[\"claude\", \"gpt4o\", \"gemini\"],\n        default=\"claude\",\n        help=\"AI model to use (default: claude)\"\n    )\n    \n    parser.add_argument(\n        \"--output\",\n        type=str,\n        help=\"Output file path for generated script (default: auto-generated)\"\n    )\n    \n    parser.add_argument(\n        \"--no-heal\",\n        action=\"store_true\",\n        help=\"Disable auto-healing if generated script fails\"\n    )\n    \n    return parser.parse_args()\n\n\nasync def main():\n    args = parse_args()\n    \n    console.print(Panel.fit(\n        \"[bold cyan]Playwright MCP Automation Script Generator[/bold cyan]\\n\"\n        f\"Model: {MODEL_CONFIGS[args.model]['display_name']}\",\n        border_style=\"cyan\"\n    ))\n    \n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n    os.makedirs(TRACE_DIR, exist_ok=True)\n    \n    model = args.model\n    task_description = args.task\n    \n    try:\n        async with PlaywrightMCPClient(MCP_SERVER_COMMAND, MCP_SERVER_ARGS) as mcp_client:\n            executor = ExecutorAgent(model, mcp_client)\n            result = await executor.execute_task(task_description)\n            \n            if not result[\"success\"]:\n                console.print(\"[bold red]âœ— Task execution failed[/bold red]\")\n                return 1\n            \n            console.print(\"\\n[bold green]âœ“ Task execution successful![/bold green]\")\n            \n            generator = CodeGeneratorAgent(model)\n            generated_code = await generator.generate_code(result[\"trace\"], task_description)\n            \n            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n            if args.output:\n                output_file = args.output\n            else:\n                safe_task_name = \"\".join(c if c.isalnum() else \"_\" for c in task_description[:30])\n                output_file = os.path.join(OUTPUT_DIR, f\"automation_{safe_task_name}_{timestamp}.py\")\n            \n            with open(output_file, \"w\") as f:\n                f.write(generated_code)\n            \n            console.print(f\"\\n[bold blue]ğŸ“„ Generated script saved to: {output_file}[/bold blue]\\n\")\n            \n            syntax = Syntax(generated_code, \"python\", theme=\"monokai\", line_numbers=True)\n            console.print(Panel(syntax, title=\"Generated Code\", border_style=\"blue\"))\n            \n            if not args.no_heal:\n                console.print(\"\\n[yellow]Testing generated script...[/yellow]\")\n                \n                proc = await asyncio.create_subprocess_exec(\n                    sys.executable, output_file,\n                    stdout=asyncio.subprocess.PIPE,\n                    stderr=asyncio.subprocess.PIPE\n                )\n                \n                stdout, stderr = await proc.communicate()\n                \n                if proc.returncode != 0:\n                    error_message = stderr.decode() if stderr else \"Unknown error\"\n                    console.print(f\"[bold red]âœ— Generated script failed with error:[/bold red]\\n{error_message}\")\n                    \n                    healer = HealerAgent(model)\n                    console.print(\"\\n[yellow]Attempting to auto-heal the script...[/yellow]\")\n                    \n                    healed_code = await healer.heal_code(generated_code, error_message)\n                    \n                    healed_output = output_file.replace(\".py\", \"_healed.py\")\n                    with open(healed_output, \"w\") as f:\n                        f.write(healed_code)\n                    \n                    console.print(f\"\\n[bold green]âœ“ Healed script saved to: {healed_output}[/bold green]\\n\")\n                    \n                    syntax = Syntax(healed_code, \"python\", theme=\"monokai\", line_numbers=True)\n                    console.print(Panel(syntax, title=\"Healed Code\", border_style=\"green\"))\n                else:\n                    console.print(\"[bold green]âœ“ Generated script executed successfully![/bold green]\")\n            \n            console.print(f\"\\n[bold cyan]Summary:[/bold cyan]\")\n            console.print(f\"  Task: {task_description}\")\n            console.print(f\"  Model: {MODEL_CONFIGS[model]['display_name']}\")\n            console.print(f\"  Output: {output_file}\")\n            console.print(f\"  Trace items: {len(result['trace'])}\")\n            \n            return 0\n            \n    except KeyboardInterrupt:\n        console.print(\"\\n[yellow]Interrupted by user[/yellow]\")\n        return 130\n    except Exception as e:\n        console.print(f\"[bold red]Error: {str(e)}[/bold red]\")\n        import traceback\n        traceback.print_exc()\n        return 1\n\n\nif __name__ == \"__main__\":\n    exit_code = asyncio.run(main())\n    sys.exit(exit_code)\n","size_bytes":5489},"SETUP.md":{"content":"# Setup and Running Instructions\n\n## Prerequisites\n\n- **Python 3.11+**\n- **Node.js 20+** (for Playwright MCP server)\n\n## Installation\n\n### 1. Install Node.js Dependencies\n\n```bash\nnpm install -g @playwright/mcp\n```\n\n### 2. Install Python Dependencies\n\n```bash\npip install -r requirements.txt\n```\n\n### 3. Install Playwright Browser\n\n```bash\nplaywright install chromium\n```\n\nOn Linux, you may also need system dependencies:\n```bash\nplaywright install-deps chromium\n```\n\n## Configuration\n\n### Set Up API Keys\n\nYou need at least one AI model API key. Set as environment variables:\n\n**For Claude (Recommended):**\n```bash\nexport ANTHROPIC_API_KEY=\"your-api-key-here\"\n```\n\n**For GPT-4o:**\n```bash\nexport OPENAI_API_KEY=\"your-api-key-here\"\n```\n\n**For Gemini:**\n```bash\nexport GEMINI_API_KEY=\"your-api-key-here\"\n```\n\nOr create a `.env` file:\n```\nANTHROPIC_API_KEY=your-api-key-here\nOPENAI_API_KEY=your-api-key-here\nGEMINI_API_KEY=your-api-key-here\n```\n\n## Running the Tool\n\n### Basic Usage\n\n```bash\npython main.py \"Navigate to example.com and click the login button\"\n```\n\n### With Different Models\n\n```bash\n# Use Claude (default, recommended)\npython main.py \"Your task description\"\n\n# Use GPT-4o\npython main.py \"Your task description\" --model gpt4o\n\n# Use Gemini\npython main.py \"Your task description\" --model gemini\n```\n\n### Additional Options\n\n```bash\n# Custom output file\npython main.py \"Your task\" --output custom_script.py\n\n# Disable auto-healing\npython main.py \"Your task\" --no-heal\n\n# Full help\npython main.py --help\n```\n\n## Example Tasks\n\n### E-commerce Automation\n```bash\npython main.py \"Go to amazon.com, search for laptop, and click the first result\"\n```\n\n### Form Filling\n```bash\npython main.py \"Navigate to example.com/contact and fill out the contact form with test data\"\n```\n\n### Web Scraping\n```bash\npython main.py \"Go to news.ycombinator.com and get the top 5 story titles\"\n```\n\n### Testing Workflow\n```bash\npython main.py \"Go to github.com, search for playwright, and click the first repository\"\n```\n\n## Output\n\nGenerated scripts are saved to `generated_scripts/` directory with timestamps:\n```\ngenerated_scripts/\nâ”œâ”€â”€ automation_Navigate_to_example_com_20251106_143022.py\nâ”œâ”€â”€ automation_Fill_out_contact_form_20251106_144533.py\nâ””â”€â”€ automation_Search_for_laptop_20251106_145612.py\n```\n\nEach script is:\n- âœ… Fully runnable standalone Python file\n- âœ… Uses async/await patterns\n- âœ… Has intelligent locators (get_by_role, get_by_label, etc.)\n- âœ… Includes proper imports and error handling\n\n## Running Generated Scripts\n\n```bash\n# Run any generated script directly\npython generated_scripts/automation_*.py\n```\n\n## Troubleshooting\n\n### \"MCP server failed to start\"\n- Ensure Node.js is installed: `node --version`\n- Verify @playwright/mcp is installed: `npm list -g @playwright/mcp`\n\n### \"Chromium browser not found\"\n```bash\nplaywright install chromium\n```\n\n### \"Missing API key\"\n- Check environment variables are set: `echo $ANTHROPIC_API_KEY`\n- Verify the key is valid and has credits\n\n### \"Import errors\"\n```bash\npip install -r requirements.txt --upgrade\n```\n\n## System Requirements\n\n### Minimum\n- Python 3.11+\n- Node.js 20+\n- 2GB RAM\n- 1GB disk space\n\n### Recommended\n- Python 3.11+\n- Node.js 20+\n- 4GB RAM\n- 2GB disk space\n- Display server (X11/Wayland for visible browser)\n\n## Architecture\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   CLI User  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜\n       â”‚\n       v\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚    main.py       â”‚ â† Entry point\nâ””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n       â”‚\n       v\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚          MCP Client                  â”‚\nâ”‚  (mcp_client.py)                     â”‚\nâ”‚  Connects to @playwright/mcp server  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n       â”‚\n       v\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚       AI Agents (agents.py)          â”‚\nâ”‚  â€¢ ExecutorAgent                     â”‚\nâ”‚  â€¢ CodeGeneratorAgent                â”‚\nâ”‚  â€¢ HealerAgent                       â”‚\nâ””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n       â”‚\n       v\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Generated Python Scripts           â”‚\nâ”‚   (generated_scripts/*.py)           â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Quick Start (Copy-Paste)\n\n```bash\n# Install everything\nnpm install -g @playwright/mcp\npip install -r requirements.txt\nplaywright install chromium\n\n# Set API key (choose one)\nexport ANTHROPIC_API_KEY=\"your-key-here\"\n\n# Run your first automation\npython main.py \"Go to example.com and click the More information link\"\n\n# Check the generated script\nls -la generated_scripts/\n```\n\n## Support\n\nFor issues with:\n- **Playwright MCP**: https://github.com/microsoft/playwright-mcp\n- **Claude API**: https://docs.anthropic.com/\n- **OpenAI API**: https://platform.openai.com/docs\n- **Gemini API**: https://ai.google.dev/docs\n","size_bytes":5440}},"version":2}