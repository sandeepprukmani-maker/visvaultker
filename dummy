import { LLMClient } from "@browserbasehq/stagehand";
import https from "https";

class CustomLLMClient extends LLMClient {
  private apiEndpoint: string;
  private apiKey: string;

  constructor(apiEndpoint: string, apiKey: string) {
    // Use a recognized provider/model format
    super("openai/gpt-4");
    this.apiEndpoint = apiEndpoint;
    this.apiKey = apiKey;
  }

  async createChatCompletion(options: any): Promise<any> {
    const { messages, temperature, maxTokens } = options.options;
    
    const requestBody = JSON.stringify({
      model: "gpt-4-1-2025-04-14-eastus-dz",
      messages,
      temperature,
      max_tokens: maxTokens,
    });

    const data = await new Promise((resolve, reject) => {
      const url = new URL(this.apiEndpoint);
      const req = https.request({
        hostname: url.hostname,
        port: url.port || 443,
        path: url.pathname,
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": `Bearer ${this.apiKey}`,
        },
        rejectUnauthorized: false,
      }, (res) => {
        let responseData = "";
        res.on("data", (chunk) => responseData += chunk);
        res.on("end", () => {
          if (res.statusCode >= 200 && res.statusCode < 300) {
            resolve(JSON.parse(responseData));
          } else {
            reject(new Error(`API error: ${res.statusCode}`));
          }
        });
      });
      
      req.on("error", reject);
      req.write(requestBody);
      req.end();
    });

    return data;
  }
}

// Usage
const oauthConfig = await fetchOAuthConfig();
const customClient = new CustomLLMClient(
  `${oauthConfig.baseURL}/chat/completions`,
  oauthConfig.apiKey
);

const stagehand = new Stagehand({
  env: "LOCAL",
  llmClient: customClient,
  verbose: 1,
  headless: false,
});
